import os
import time
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
import faiss
from langchain_ollama import ChatOllama
from langchain_huggingface import HuggingFaceEmbeddings

from langchain_classic.chains import RetrievalQA

import utils

print(f'faiss VERSION : {faiss.__version__}, í˜„ìž¬ ì‹œê°„ : {utils.timestamp()}')

INDEX_PATH_BOOKS30 = "faiss_index_books30"

###########################
# ì‹œìž‘ ì‹œê°„ ê¸°ë¡
start_time = time.time()

# ðŸ“š 100ê¶Œ ì†Œì„¤ì±… ë¡œë“œ (ì˜ˆ: books í´ë” ì•ˆì— book1.txt ~ book100.txt)
documents = []
books_dir = "books30"   # ì†Œì„¤ì±… í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ì´ ë“¤ì–´ìžˆëŠ” í´ë”
book_files = [f for f in os.listdir(books_dir) if f.endswith(".txt")]

print(f"ì´ {len(book_files)}ê¶Œì˜ ì±…ì„ ë¡œë“œí•©ë‹ˆë‹¤.")

for file in book_files:
    loader = TextLoader(os.path.join(books_dir, file), encoding="utf-8")
    documents.extend(loader.load())

elapsed = time.time() - start_time
print(f"1 ë¬¸ì„œ ê°ì²´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ê²½ê³¼ ì‹œê°„: {elapsed:.4f}ì´ˆ)")

###########################
# 1 ë¬¸ì„œ ë¶„í• 
start_time = time.time()
text_splitter = CharacterTextSplitter(
    separator=" ",
    chunk_size=500,
    chunk_overlap=50
)
docs = text_splitter.split_documents(documents)
elapsed = time.time() - start_time
print(f"2 ë¬¸ì„œ ë¶„í•  (ê²½ê³¼ ì‹œê°„: {elapsed:.4f}ì´ˆ)")
print(f'ë¶„í• ëœ ë¬¸ì„œ ê°¯ìˆ˜ : {len(docs)}')

###########################
# 3. HuggingFace Embeddings ì´ˆê¸°í™”
start_time = time.time()
embeddings = HuggingFaceEmbeddings(
    model_name="BAAI/bge-m3",
    model_kwargs={"device": "cpu"}    # GPU ì‚¬ìš© ì‹œ "cuda"
)
elapsed = time.time() - start_time
print(f"3 HuggingFace Embeddings ì´ˆê¸°í™” (ê²½ê³¼ ì‹œê°„: {elapsed:.4f}ì´ˆ)")

###########################
# 4. ë²¡í„° ë³€í™˜ ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
if os.path.exists(INDEX_PATH_BOOKS30):
    start_time = time.time()
    vectorstore = FAISS.load_local(INDEX_PATH_BOOKS30, embeddings, allow_dangerous_deserialization=True)
    elapsed = time.time() - start_time
    print(f"4 ì €ìž¥ëœ FAISS ì¸ë±ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ (ê²½ê³¼ ì‹œê°„: {elapsed:.4f}ì´ˆ)")
else:
    start_time = time.time()
    vectorstore = FAISS.from_documents(docs, embeddings)
    elapsed = time.time() - start_time
    print(f"FAISS ì¸ë±ìŠ¤ ìƒˆë¡œ ìƒì„± ì™„ë£Œ (ê²½ê³¼ ì‹œê°„: {elapsed:.4f}ì´ˆ)")
    vectorstore.save_local(INDEX_PATH_BOOKS30)
    print(f"4 ì¸ë±ìŠ¤ë¥¼ '{INDEX_PATH_BOOKS30}' í´ë”ì— ì €ìž¥í–ˆìŠµë‹ˆë‹¤.")
print(f'í˜„ìž¬ ì‹œê°„ : {utils.timestamp()}')

###########################
# 5. ChatOllama + RetrievalQA ì—°ê²°
llm = ChatOllama(model="mistral")
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever(),
    chain_type="stuff"
)

###########################
# 6. ì§ˆë¬¸ ì‹¤í–‰
# start_time = time.time()
# query = "ì£¼ì¸ê³µì˜ ì§ì—…ì€ ë¬´ì—‡ì¸ê°€? Please answer in Korean"
# answer = qa_chain.invoke(query)
# elapsed = time.time() - start_time
#
# print(f'ì§ˆë¬¸ : {query}')
# print(f'ë‹µë³€ : {answer}')
# print(f"6 ChatOllama QA ì‹¤í–‰ (ê²½ê³¼ ì‹œê°„: {elapsed:.4f}ì´ˆ)")
# print(f'í˜„ìž¬ ì‹œê°„ : {utils.timestamp()}')


###########################
# 7. CLI ëŒ€í™” ë£¨í”„
def chat_cli():
    print("RAG ì±—ë´‡ ì‹œìž‘! ì§ˆë¬¸ì„ ìž…ë ¥í•˜ì„¸ìš”. (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ìž…ë ¥)")
    while True:
        question = input("ì§ˆë¬¸ > ").strip()
        if question.lower() in ["exit", "quit", "ì¢…ë£Œ"]:
            print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        start_t = time.time()
        answer_q = qa_chain.invoke(question + " Please answer in Korean")
        elapsed_t = time.time() - start_t
        print(f"ChatOllama QA ì‹¤í–‰ (ê²½ê³¼ ì‹œê°„: {elapsed_t:.4f}ì´ˆ)")
        print("ë‹µë³€ >", answer_q)


chat_cli()
